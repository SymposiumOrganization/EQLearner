{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization process\n",
    "Given the output of DatasetCreator (dictionary) create a nested dictionary with numbers for each lemma "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, just import the libraries, create an object from the DatasetCreator and generate a random function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b2d4db9c0fbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfun_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetCreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasis_functions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_linear_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_binomial_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_compositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_N_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdivision_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfun_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\\n String format:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nDictionary formatt (consistent in the order): \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'string' is not defined"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "\n",
    "from eq_learner.DatasetCreator import DatasetCreator\n",
    "from sympy import sin, Symbol, log, exp \n",
    "import numpy as np\n",
    "\n",
    "x = Symbol('x')\n",
    "basis_functions = [x,sin,log,exp]\n",
    "fun_generator = DatasetCreator(basis_functions,max_linear_terms=1, max_binomial_terms=1,max_compositions=1,max_N_terms=1,division_on=False)\n",
    "string, dictionary =  fun_generator.generate_fun()\n",
    "print(\"\\n\\n\\n String format:\", string)\n",
    "print(\"\\n\\nDictionary formatt (consistent in the order): \\n\", dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eq_learner.processing import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is organized as three step process: \n",
    "First we segment each element of our mathematical expression, then we map each unique element of the expression to a number and finally we create a list with the labels.\n",
    "<ul>\n",
    "<li>\n",
    "extract_terms does the first task.\n",
    "<li>\n",
    "numberize_terms does the second task.\n",
    "<li> \n",
    "flatten_seq does the third task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Single': [['utf-8', 'log', '(', 'x', ')', '', '']], 'binomial': [['utf-8', 'exp', '(', 'x', ')', '*', 'log', '(', 'x', ')', '', '']], 'N_terms': [['utf-8', 'exp', '(', '2', '*', 'x', ')', '*', 'sin', '(', 'x', ')', '**', '2', '', '']], 'compositions': [['utf-8', 'log', '(', 'x', '**', '2', '+', 'sin', '(', 'x', ')', '+', '1', ')', '', '']], 'division': []}\n"
     ]
    }
   ],
   "source": [
    "tmp = tokenization.extract_terms(dictionary)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Single': [[4, 5, 1, 6]], 'binomial': [[3, 5, 1, 6, 8, 4, 5, 1, 6]], 'N_terms': [[3, 5, 15, 8, 1, 6, 8, 2, 5, 1, 6, 7, 15]], 'compositions': [[4, 5, 1, 7, 15, 9, 2, 5, 1, 6, 9, 14, 6]], 'division': []}\n"
     ]
    }
   ],
   "source": [
    "tmp = tokenization.numberize_terms(tmp)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 4, 5, 1, 6, 9, 3, 5, 1, 6, 8, 4, 5, 1, 6, 9, 3, 5, 15, 8, 1, 6, 8, 2, 5, 1, 6, 7, 15, 9, 4, 5, 1, 7, 15, 9, 2, 5, 1, 6, 9, 14, 6, 13]\n"
     ]
    }
   ],
   "source": [
    "final = tokenization.flatten_seq(tmp)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some details regaring the tokenized sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tokens Words\n",
       "0       -1      \n",
       "1        4   log\n",
       "2        5     (\n",
       "3        1     x\n",
       "4        6     )\n",
       "5        9     +\n",
       "6        3   exp\n",
       "7        5     (\n",
       "8        1     x\n",
       "9        6     )\n",
       "10       8     *\n",
       "11       2   sin\n",
       "12       5     (\n",
       "13       1     x\n",
       "14       6     )\n",
       "15       9     +\n",
       "16       1     x\n",
       "17       8     *\n",
       "18       2   sin\n",
       "19       5     (\n",
       "20       1     x\n",
       "21       6     )\n",
       "22       7    **\n",
       "23      13     2\n",
       "24       9     +\n",
       "25       4   log\n",
       "26       5     (\n",
       "27       3   exp\n",
       "28       5     (\n",
       "29      13     2\n",
       "30       8     *\n",
       "31       1     x\n",
       "32       6     )\n",
       "33       6     )\n",
       "34      -2      "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"len:\", len(final))\n",
    "series = pd.DataFrame({\"Tokens\": final, \"Words\":  tokenization.apply_inverse_mapping(final)})\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokens  Words\n",
       " 6      )        6\n",
       " 5      (        6\n",
       " 1      x        6\n",
       " 9      +        3\n",
       " 8      *        3\n",
       " 13     2        2\n",
       " 4      log      2\n",
       " 3      exp      2\n",
       " 2      sin      2\n",
       " 7      **       1\n",
       "-1               1\n",
       "-2               1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prove that everything went smoothly we can go back with get_string method to a string based representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: x*sin(x)**2 + exp(x)*sin(x) + log(x) + log(exp(2*x)) \n",
      "\n",
      "\n",
      "Result: log(x)+exp(x)*sin(x)+x*sin(x)**2+log(exp(2*x))\n"
     ]
    }
   ],
   "source": [
    "print(\"original:\", str(string), \"\\n\\n\")\n",
    "\n",
    "print(\"Result:\", tokenization.get_string(final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that has been done before for a single expression, can be applied as well for batches with automatic padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Single': [log(x)],\n",
       "  'binomial': [exp(x)*sin(x)],\n",
       "  'N_terms': [sin(x)**6],\n",
       "  'compositions': [exp(x*sin(x) + x)],\n",
       "  'division': []},\n",
       " {'Single': [log(x)],\n",
       "  'binomial': [exp(x)*log(x)],\n",
       "  'N_terms': [x**3*log(x)**3],\n",
       "  'compositions': [sin(x*log(x) + 1)],\n",
       "  'division': []},\n",
       " {'Single': [log(x)],\n",
       "  'binomial': [exp(x)*sin(x)],\n",
       "  'N_terms': [exp(5*x)],\n",
       "  'compositions': [log(sin(x)**2 + sin(x))],\n",
       "  'division': []},\n",
       " {'Single': [log(x)],\n",
       "  'binomial': [x*log(x)],\n",
       "  'N_terms': [x**2*log(x)**2],\n",
       "  'compositions': [sin(x*exp(x) + 1)],\n",
       "  'division': []},\n",
       " {'Single': [log(x)],\n",
       "  'binomial': [exp(x)*log(x)],\n",
       "  'N_terms': [x**3],\n",
       "  'compositions': [0],\n",
       "  'division': []},\n",
       " {'Single': [sin(x)],\n",
       "  'binomial': [exp(x)*sin(x)],\n",
       "  'N_terms': [exp(4*x)],\n",
       "  'compositions': [sin(1)],\n",
       "  'division': []},\n",
       " {'Single': [sin(x)],\n",
       "  'binomial': [exp(2*x)],\n",
       "  'N_terms': [x**5],\n",
       "  'compositions': [exp(x*sin(x))],\n",
       "  'division': []},\n",
       " {'Single': [sin(x)],\n",
       "  'binomial': [sin(x)**2],\n",
       "  'N_terms': [sin(x)**4],\n",
       "  'compositions': [E],\n",
       "  'division': []},\n",
       " {'Single': [x],\n",
       "  'binomial': [x*sin(x)],\n",
       "  'N_terms': [x**3*exp(3*x)],\n",
       "  'compositions': [sin(x**2 + x + 1)],\n",
       "  'division': []},\n",
       " {'Single': [log(x)],\n",
       "  'binomial': [x*log(x)],\n",
       "  'N_terms': [x**4],\n",
       "  'compositions': [sin(exp(2*x))],\n",
       "  'division': []},\n",
       " {'Single': [log(x)],\n",
       "  'binomial': [exp(x)*log(x)],\n",
       "  'N_terms': [x**3*exp(x)],\n",
       "  'compositions': [exp(sin(x)**2 + sin(x) + 1)],\n",
       "  'division': []},\n",
       " {'Single': [log(x)],\n",
       "  'binomial': [x**2],\n",
       "  'N_terms': [sin(x)**5],\n",
       "  'compositions': [exp(x + 1)],\n",
       "  'division': []},\n",
       " {'Single': [log(x)],\n",
       "  'binomial': [x**2],\n",
       "  'N_terms': [exp(5*x)],\n",
       "  'compositions': [log(x**2 + sin(x) + 1)],\n",
       "  'division': []},\n",
       " {'Single': [sin(x)],\n",
       "  'binomial': [exp(2*x)],\n",
       "  'N_terms': [log(x)**3],\n",
       "  'compositions': [sin(1)],\n",
       "  'division': []},\n",
       " {'Single': [sin(x)],\n",
       "  'binomial': [x*sin(x)],\n",
       "  'N_terms': [log(x)**2*sin(x)**2],\n",
       "  'compositions': [exp(sin(x)**2 + 1)],\n",
       "  'division': []},\n",
       " {'Single': [sin(x)],\n",
       "  'binomial': [x*log(x)],\n",
       "  'N_terms': [sin(x)**4],\n",
       "  'compositions': [log(exp(2*x) + sin(x) + 1)],\n",
       "  'division': []},\n",
       " {'Single': [sin(x)],\n",
       "  'binomial': [x*log(x)],\n",
       "  'N_terms': [x**3*exp(x)],\n",
       "  'compositions': [E],\n",
       "  'division': []},\n",
       " {'Single': [sin(x)],\n",
       "  'binomial': [log(x)*sin(x)],\n",
       "  'N_terms': [x**2*sin(x)**4],\n",
       "  'compositions': [sin(exp(2*x))],\n",
       "  'division': []},\n",
       " {'Single': [sin(x)],\n",
       "  'binomial': [sin(x)**2],\n",
       "  'N_terms': [log(x)**4*sin(x)**2],\n",
       "  'compositions': [E],\n",
       "  'division': []},\n",
       " {'Single': [exp(x)],\n",
       "  'binomial': [exp(x)*sin(x)],\n",
       "  'N_terms': [exp(6*x)],\n",
       "  'compositions': [log(x*sin(x) + 1)],\n",
       "  'division': []}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_generator = DatasetCreator(basis_functions,max_linear_terms=1, max_binomial_terms=1,max_compositions=1,max_N_terms=1,division_on=False)\n",
    "support = np.arange(-20,20,0.1)\n",
    "string, dictionary =  fun_generator.generate_batch(support,20)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f83ba1fe304a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/CSEM_repos/New-EQ-learn/lib/src/eq_learner/processing/tokenization.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;34m\"\"\"Just the extract_terms, numberize_terms and flatten_seq methods set up after the other plus a padding to the longest sequence (pad symbol 0)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/CSEM_repos/New-EQ-learn/lib/src/eq_learner/processing/tokenization.py\u001b[0m in \u001b[0;36m_sequence\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtmp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumberize_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mflatten_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/CSEM_repos/New-EQ-learn/lib/src/eq_learner/processing/tokenization.py\u001b[0m in \u001b[0;36mextract_terms\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mseparated_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#tokenized_dict = {}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mli\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mseparated_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#tokenized_list = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "tokenization.pipeline(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
