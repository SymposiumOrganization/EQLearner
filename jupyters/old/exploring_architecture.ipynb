{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597210856767",
   "display_name": "Python 3.7.6 64-bit ('env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a simple jupyter to study stuff (embedding and attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self):\n",
    "        layer = torch.nn.Embedding(3,2)\n",
    "        final_layer = nn.Linear(2,1)\n",
    "        activation_fun = nn.Sigmoid(final)\n",
    "    def __call__(inp):\n",
    "        partial = layer(sol)\n",
    "        final = nn.Sigmoid(final_layer(partial))\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[1],[2],[3],[0]], dtype=torch.long)\n",
    "sol =  torch.tensor([1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The two layers\n",
    "layer = torch.nn.Embedding(4,2)\n",
    "final_layer = nn.Linear(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[ 1.4803,  0.9578]],\n\n        [[ 1.9680,  1.0638]],\n\n        [[-0.4979,  0.5636]],\n\n        [[ 1.3821, -0.2303]]], grad_fn=<EmbeddingBackward>)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "layer(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1, 0, 4, 3],\n        [1, 2, 3, 0]])\ntensor([[0, 1],\n        [0, 1]])\n"
    }
   ],
   "source": [
    "src = torch.tensor([[1,0,4,3],[1,2,3,0]],dtype=torch.long)\n",
    "pos = torch.arange(0, src.shape[1]).unsqueeze(0).repeat(2, 1)\n",
    "print(src)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_attention(self, embedded, conved, encoder_conved, encoder_combined):\n",
    "    \n",
    "    #embedded = [batch size, trg len, emb dim]\n",
    "    #conved = [batch size, hid dim, trg len]\n",
    "    #encoder_conved = encoder_combined = [batch size, src len, emb dim]\n",
    "    \n",
    "    #permute and convert back to emb dim\n",
    "    conved_emb = self.attn_hid2emb(conved.permute(0, 2, 1))\n",
    "    \n",
    "    #conved_emb = [batch size, trg len, emb dim]\n",
    "    \n",
    "    combined = (conved_emb + embedded) * self.scale\n",
    "    \n",
    "    #combined = [batch size, trg len, emb dim]\n",
    "            \n",
    "    energy = torch.matmul(combined, encoder_conved.permute(0, 2, 1))\n",
    "    \n",
    "    #energy = [batch size, trg len, src len]\n",
    "    \n",
    "    attention = F.softmax(energy, dim=2)\n",
    "    \n",
    "    #attention = [batch size, trg len, src len]\n",
    "        \n",
    "    attended_encoding = torch.matmul(attention, encoder_combined)\n",
    "    \n",
    "    #attended_encoding = [batch size, trg len, emd dim]\n",
    "    \n",
    "    #convert from emb dim -> hid dim\n",
    "    attended_encoding = self.attn_emb2hid(attended_encoding)\n",
    "    \n",
    "    #attended_encoding = [batch size, trg len, hid dim]\n",
    "    \n",
    "    #apply residual connection\n",
    "    attended_combined = (conved + attended_encoding.permute(0, 2, 1)) * self.scale\n",
    "    \n",
    "    #attended_combined = [batch size, hid dim, trg len]\n",
    "    \n",
    "    return attention, attended_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}